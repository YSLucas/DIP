{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIP opdracht 2: Letterfrequenties\n",
    "Lucas Siekk√∂tter, 1770991 <br>\n",
    "& <br>\n",
    "Wijnand van Dijk, 1762733 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is een notebook om onze code te demonstreren en te illustreren. We laten alle functies zien en relevante resultaten om te laten zien dat de gewenste resultaten aanwezig zijn. We kijken per file naar de functies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### info.py\n",
    "Maakt een lijst met alle leestekens, die lijst kunnen we later gebruiken om makkelijk alle leesteken te vervangen. Ook wordt er een lijst aangemaakt van ons 'alfabet' die bestaat uit het normale alfabet plus '_' en '%'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "leestekens = [\".\", \",\", \":\", \";\", \"\\'\", \"\\\"\", \"-\", \"_\", \"!\", \"?\", \"(\", \")\", \"\\\\\"]\n",
    "\n",
    "abc = list(string.ascii_lowercase)\n",
    "abc.extend([\"_\", \"%\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapper.py\n",
    "De functie `mapper_get_lines()` lijst de hele tekst uit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_get_lines(path):\n",
    "    \"\"\"\n",
    "    Converts .txt to strings and puts it in a list\n",
    "    \n",
    "    @param path: path to text data\n",
    "    @return    : list\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    with open(\"data/\" + path + \".txt\", \"r\", encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line != \"\":\n",
    "                res.append(line)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mapper_replace_punct()` zorgt ervoor dat alle leestekens met '%' worden vervanfen, en spaties met '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_replace_punct(text, sign):\n",
    "    \"\"\"\n",
    "    Replace all punctuation with % and replace spaces with _\n",
    "    \n",
    "    @param  sign: leestekens\n",
    "    @return     : text waar leestekens vervangen zijn\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for line in text:\n",
    "        for i in sign:\n",
    "            line = line.replace(i, \"%\")\n",
    "        \n",
    "        line = line.replace(\" \", \"_\")\n",
    "        line = line.lower()\n",
    "        res.append(line)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter.py\n",
    "`filter_training()` is een filter functie die is bedoeld voor de trainings fase. De functie kijkt bij alle letters in een tekst welke letter of leesteken volgt. Combinaties van leesteken en spatie halen we eruit, omdat dat volgens ons niks zegt over de taal van een zin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_training(txt):\n",
    "    \"\"\"\n",
    "    Get all 2 letter combinations in text\n",
    "    \n",
    "    @param  txt: tekst waat combinaties uit gehaald worden\n",
    "    @return    : lijst met combinaties in tekst\n",
    "    \"\"\"\n",
    "    combinations = []\n",
    "    for line in txt:\n",
    "        for letter in range(0, len(line)):  \n",
    "            try:\n",
    "                res = line[letter] + line[letter + 1]\n",
    "                # leesteken + spatie is niet relevant dus die combinaties kunnen eruit. \"\\n\" zitten er ook tussen en die kunnen ook weg\n",
    "                # en check of beide letters wel in het (aangepaste) alfabet zitten\n",
    "                if (res[0] in abc and res[-1] in abc) and (res != \"%_\" and res != \"_%\" and \"\\n\" not in res):\n",
    "                    combinations.append([res])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filter_validation()` is de functie voor de validatie fase. De reden dat er twee functies zijn gemaakt die bijna hetzelfde doen is dat de vorm van input tijdens de training- en validatiefase anders is. Dat komt omdat tijdens de validatie de tekst per line is ingedeeld, en tijdens training is dat niet zo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_validation(txt):\n",
    "    \"\"\"\n",
    "    Get all 2 letter combinations in text.\n",
    "    \n",
    "    Different funtion was made to return in correct form\n",
    "    \n",
    "    @param  txt: tekst waat combinaties uit gehaald worden\n",
    "    @return    : lijst met combinaties in tekst\n",
    "    \"\"\"\n",
    "    combinations = []\n",
    "    for line in txt:\n",
    "        temp = []\n",
    "        for letter in range(0, len(line)):  \n",
    "            try:\n",
    "                res = line[letter] + line[letter + 1]\n",
    "                # leesteken + spatie is niet relevant dus die combinaties kunnen eruit. \"\\n\" zitten er ook tussen en die kunnen ook weg\n",
    "                # en check of beide letters wel in het (aangepaste) alfabet zitten\n",
    "                if (res[0] in abc and res[-1] in abc) and (res != \"%_\" and res != \"_%\" and \"\\n\" not in res):\n",
    "                    temp.append(res)\n",
    "            except:\n",
    "                continue\n",
    "        combinations.append(temp)\n",
    "    \n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reducer.py\n",
    "\n",
    "We hebben onze methode gebaseerd op een comment uit de volgende blogpost: https://stackoverflow.com/a/18197422. De comment in kwestie is: \n",
    "\n",
    "\n",
    "```\n",
    "'Take the Wikipedia in English. Check what is the probability that after the letter 'a' comes a 'b' (for example) and do that for all the combination of letters, you will end up with a matrix of probabilities.\n",
    "\n",
    "If you do the same for the Wikipedia in different languages you will get different matrices for each language.\n",
    "\n",
    "To detect the language just use all those matrices and use the probabilities as a score, let say that in English you'd get this probabilities:\n",
    "\n",
    "t->h = 0.3 h->e = .2\n",
    "\n",
    "and in the Spanish matrix you'd get that\n",
    "\n",
    "t->h = 0.01 h->e = .3\n",
    "\n",
    "The word 'the', using the English matrix, would give you a score of 0.3+0.2 = 0.5 and using the Spanish one: 0.01+0.3 = 0.31\n",
    "\n",
    "The English matrix wins so that has to be English.\n",
    "```\n",
    "\n",
    "`reducer()` Maakt een matrix met van 28 bij 28 (ons alfabet is 28 lang) en vult per combinatie in hoevaak die voorkomt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(c):\n",
    "    \"\"\"\n",
    "    When a combination occurs, update matrix in the right place\n",
    "    \n",
    "    @param c: list of combinations found in text\n",
    "    @return : matrix with combination frequencies\n",
    "    \"\"\"\n",
    "    matrix = numpy.zeros((28, 28))\n",
    "    for combination in c:\n",
    "        left, right = combination[0], combination[-1]\n",
    "        try:\n",
    "            matrix[abc.index(left)][abc.index(right)] += 1 # find right place in matrix and add 1\n",
    "        except:\n",
    "            # double check: if one of the letters isnt in the alphabet skip this one and continue\n",
    "            continue \n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reducer_chance_matrix()` gebruikt de door `reducer()` gemaakte matrix om een matrix te maken met de kans dat een combinatie voorkomt. `reducer_chance_matrix()` en `reducer()` worden gebruikt in de trainings fase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer_chance_matrix(m):\n",
    "    \"\"\"\n",
    "    Convert a frequence matrix to a chance matrix\n",
    "    \n",
    "    @param m: frequencie matrix\n",
    "    @return : chance matrix\n",
    "    \"\"\"\n",
    "    total = numpy.sum(m) # total letter combinations analysed\n",
    "    \n",
    "    with numpy.nditer(m, op_flags=['readwrite']) as it:\n",
    "        for x in it:\n",
    "            if x != 0:\n",
    "                x[...] = round(x / total * 100, 4) # chance x to its chance that it occurs\n",
    "   \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reducer_final()` is een functie voor de validatie. Deze functie voorspelt met behulp van de kans matrices van `reducer_chance_matrix()` of een zin Nederlands of Engels is. Voor een specifieke uitleg over hoe het in zn werking gaat kan je de comments in de onderstaande functie lezen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer_final(eng_m, nl_m, c):\n",
    "    \"\"\"\n",
    "    method: https://stackoverflow.com/a/18197422\n",
    "    \n",
    "    @param eng_m: english trained matrix numpy array\n",
    "    @param nl_m: dutch trained matrix numpy array\n",
    "    @param c: list van combinaties die voorkomen per zin\n",
    "    \"\"\"\n",
    "    nl_count = 0    # houdt bij hoeveel nederlandse zinnen er zijn gevonden\n",
    "    eng_count = 0   # houdt bij hoveel engelse zinnen er zijn gevonden\n",
    "    for line in c:  # loopt door de tekst heen per line\n",
    "        # De matrices zijn gevuld met kansen. Per combinatie die in een zin voorkomt\n",
    "        # pakt het algoritme de bijbehorende kans en telt die bij de totale kans dat een\n",
    "        # zin nederlands of engels is op. De taal met het hoogste getal aan het einde \n",
    "        # wordt als waarheid genomen.\n",
    "        eng = 0   \n",
    "        nl = 0\n",
    "        for combination in line:\n",
    "            left, right = abc.index(combination[0]), abc.index(combination[-1]) # vind juiste index voor matrices\n",
    "            oem = eng_m[left][right]    # On English Matrix. De kans dat de combinatie voorkomt in het engels\n",
    "            odm = nl_m[left][right]     # On Dutch Matrix. De kans dat de combinatie voorkomt in het engels\n",
    "            eng += oem  # tel de kans op bij het totaal (voor sepcifieke zin)\n",
    "            nl += odm\n",
    "        \n",
    "        # er is nu een complete zin gecheckt -> kijk welk getal groter is en tel √©√©n bij de telling op\n",
    "        # Een gelijkspel zal zeer waarschijnlijk niet voorkomen omdat de kansen op 3 decimalen zijn afgerond\n",
    "        if eng > nl:\n",
    "            eng_count += 1\n",
    "        else:\n",
    "            nl_count += 1\n",
    "        \n",
    "        #reset waardes voor zin en ga door naar de volgende zin\n",
    "        eng, nl = 0, 0  \n",
    "    \n",
    "    return nl_count, eng_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_matrix.py\n",
    "Hier worden de matrices getraind, en worden ze opgeslagen als een .npy bestand.\n",
    "Met behulp van een paart `print()` statements laten we zien dat de gewenste resultaten worden behaald."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = ['eng', 'nl']\n",
    "\n",
    "\n",
    "def train_matrix(txt, lang):\n",
    "    \"\"\"\n",
    "    Calls right functions to make and save a chance matrix\n",
    "    \n",
    "    @param  txt: list of combinations found in text\n",
    "    @param lang: Language configuration\n",
    "    \"\"\"\n",
    "    matrix = numpy.zeros((28, 28))\n",
    "    for line in txt:\n",
    "        m = reducer(line)\n",
    "        matrix = numpy.add(matrix, m)\n",
    "    \n",
    "    chance_m = reducer_chance_matrix(matrix)\n",
    "\n",
    "#     numpy.save(\"trained_matrix/\" + lang + \"_trained\", chance_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstratie mapper functies.\n",
      "Before: ÔªøThe Project Gutenberg eBook of Metamorphosis, by Franz Kafka \n",
      "After mapper.py: Ôªøthe_project_gutenberg_ebook_of_metamorphosis%_by_franz_kafka \n",
      "\n",
      "Demonstratie filter functies. \n",
      "Dit is hoe de combinaties van de vorige zin eruit zien:\n",
      "[['th'], ['he'], ['e_'], ['_p'], ['pr'], ['ro'], ['oj'], ['je'], ['ec'], ['ct'], ['t_'], ['_g'], ['gu'], ['ut'], ['te'], ['en'], ['nb'], ['be'], ['er'], ['rg'], ['g_'], ['_e'], ['eb'], ['bo'], ['oo'], ['ok'], ['k_'], ['_o'], ['of'], ['f_'], ['_m'], ['me'], ['et'], ['ta'], ['am'], ['mo'], ['or'], ['rp'], ['ph'], ['ho'], ['os'], ['si'], ['is'], ['s%'], ['_b'], ['by'], ['y_'], ['_f'], ['fr'], ['ra']]\n",
      "\n",
      "\n",
      "\n",
      "Demonstratie mapper functies.\n",
      "Before: The Project Gutenberg EBook of Alleen op de Wereld, by Hector Malot \n",
      "After mapper.py: the_project_gutenberg_ebook_of_alleen_op_de_wereld%_by_hector_malot \n",
      "\n",
      "Demonstratie filter functies. \n",
      "Dit is hoe de combinaties van de vorige zin eruit zien:\n",
      "[['th'], ['he'], ['e_'], ['_p'], ['pr'], ['ro'], ['oj'], ['je'], ['ec'], ['ct'], ['t_'], ['_g'], ['gu'], ['ut'], ['te'], ['en'], ['nb'], ['be'], ['er'], ['rg'], ['g_'], ['_e'], ['eb'], ['bo'], ['oo'], ['ok'], ['k_'], ['_o'], ['of'], ['f_'], ['_a'], ['al'], ['ll'], ['le'], ['ee'], ['en'], ['n_'], ['_o'], ['op'], ['p_'], ['_d'], ['de'], ['e_'], ['_w'], ['we'], ['er'], ['re'], ['el'], ['ld'], ['d%']]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Train function. Uses outputs from a function as inputs to the next to produce two trained matrices.\n",
    "    \"\"\"\n",
    "\n",
    "    for x in LANGUAGES:\n",
    "        path = \"train_\" + x + \"/train_data\"\n",
    "        \n",
    "        lines_list = mapper_get_lines(path)\n",
    "        updated_text = mapper_replace_punct(lines_list, leestekens)\n",
    "        \n",
    "        combi_list = filter_training(updated_text)\n",
    "        \n",
    "        print(f'Demonstratie mapper functies.\\nBefore: {lines_list[0]} \\nAfter mapper.py: {updated_text[0]} \\n')\n",
    "        print(f'Demonstratie filter functies. \\nDit is hoe de combinaties van de vorige zin eruit zien:\\n{combi_list[0:50]}\\n\\n\\n')\n",
    "\n",
    "        train_matrix(combi_list, x)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main.py\n",
    "Dit is de main functie, hier wordt alles in beweging gezet en uitgevoerd, ook wordt de uitkomst hier weergegeven.\n",
    "Ook wordt hier weergegeven hoe de zin eruit ziet nadat alle spaties en leestekens weggehaald zijn, en daarna worden alle combinaties van die zin weergegeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstratie mapper functies.\n",
      "Before: time be generously rewarded by NASA.  Young descended those final few \n",
      "After mapper.py: time_be_generously_rewarded_by_nasa%__young_descended_those_final_few \n",
      "\n",
      "Demonstratie filter functies. \n",
      "Dit is hoe de combinaties van de vorige zin eruit zien:\n",
      "['ti', 'im', 'me', 'e_', '_b', 'be', 'e_', '_g', 'ge', 'en', 'ne', 'er', 'ro', 'ou', 'us', 'sl', 'ly', 'y_', '_r', 're', 'ew', 'wa', 'ar', 'rd', 'de', 'ed', 'd_', '_b', 'by', 'y_', '_n', 'na', 'as', 'sa', 'a%', '__', '_y', 'yo', 'ou', 'un', 'ng', 'g_', '_d', 'de', 'es', 'sc', 'ce', 'en', 'nd', 'de', 'ed', 'd_', '_t', 'th', 'ho', 'os', 'se', 'e_', '_f', 'fi', 'in', 'na', 'al', 'l_', '_f', 'fe', 'ew']\n",
      "\n",
      "\n",
      "\n",
      "In deze tekst zijn 74 Nederlandse zinnen gevonden, en 117 Engelse zinnen.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function. Uses outputs from a function as inputs to the next.\n",
    "    \"\"\"\n",
    "\n",
    "    lines_list = mapper_get_lines(\"validation\")\n",
    "    updated_text = mapper_replace_punct(lines_list, leestekens)\n",
    "\n",
    "    combi_list = filter_validation(updated_text)\n",
    "\n",
    "    nl, eng = numpy.load('trained_matrix/nl_trained.npy'), numpy.load('trained_matrix/eng_trained.npy')\n",
    "    result = reducer_final(eng, nl, combi_list)\n",
    "    \n",
    "    print(f'Demonstratie mapper functies.\\nBefore: {lines_list[0]} \\nAfter mapper.py: {updated_text[0]} \\n')\n",
    "    print(f'Demonstratie filter functies. \\nDit is hoe de combinaties van de vorige zin eruit zien:\\n{combi_list[0]}\\n\\n\\n')\n",
    "    \n",
    "    print(f'In deze tekst zijn {result[0]} Nederlandse zinnen gevonden, en {result[1]} Engelse zinnen.')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultaat\n",
    "Het streven was om in de validatie tesks 73 Nederlandse en 119 Engelse zinnen te herkennen. Ons resultaat laat zien dat onze code niet exact alle zinnen goed kan indelen, maar hij zit wel heel erg in de buurt van een 100% score. We zijn zelf tevreden met het resultaat van ons model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
