{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIP opdracht 2: Letterfrequenties\n",
    "Lucas Siekkötter, 1770991\n",
    "&\n",
    "Wijnand van Dijk, 1762733 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### info.py\n",
    "Maakt een lijst met alle leestekens, die lijst kunnen we later gebruiken om makkelijk alle leesteken te vervangen. Ook wordt er een lijst aangemaakt van ons 'alfabet' die bestaat uit het normale alfabet plus '_' en '%'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "leestekens = [\".\", \",\", \":\", \";\", \"\\'\", \"\\\"\", \"-\", \"_\", \"!\", \"?\", \"(\", \")\", \"\\\\\"]\n",
    "\n",
    "abc = list(string.ascii_lowercase)\n",
    "abc.extend([\"_\", \"%\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapper.py\n",
    "De functie 'mapper_get_lines' lijst de hele tekst uit. \n",
    "\n",
    "'mapper_replace_punct' zorgt ervoor dat alle leestekens en spaties vervangen worden, '_' inplaats van een spatie en '%' inplaats van een leesteken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_get_lines(path):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    with open(\"data/\" + path + \".txt\", \"r\", encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line != \"\":\n",
    "                res.append(line)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_replace_punct(text, sign):\n",
    "    \"\"\"\n",
    "    Replace all punctuation with % and replace spaces with _\n",
    "    @param  sign: leestekens\n",
    "    @return     : text waar leestekens vervangen zijn\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for line in text:\n",
    "        for i in sign:\n",
    "            line = line.replace(i, \"%\")\n",
    "        \n",
    "        line = line.replace(\" \", \"_\")\n",
    "        line = line.lower()\n",
    "        res.append(line)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter.py\n",
    "'filter_training' geeft een lijst van alle letter combinaties die in de zin voorkomen, dus niet de combinaties die een leesteken of spatie bevatten (of wat daar voor in de plaats staat).\n",
    "\n",
    "'filter_validation' doet eigenlijk hetzelfde alleen geeft hij het in een andere form terug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_training(txt):\n",
    "    \"\"\"\n",
    "    Get all 2 letter combinations in text\n",
    "    @param  txt: tekst waat combinaties uit gehaald worden\n",
    "    @return    : lijst met combinaties in tekst\n",
    "    \"\"\"\n",
    "    combinations = []\n",
    "    for line in txt:\n",
    "        for letter in range(0, len(line)):  \n",
    "            try:\n",
    "                res = line[letter] + line[letter + 1]\n",
    "                # leesteken + spatie is niet relevant dus die combinaties kunnen eruit. \"\\n\" zitten er ook tussen en die kunnen ook weg\n",
    "                # en check of beide letters wel in het (aangepaste) alfabet zitten\n",
    "                if (res[0] in abc and res[-1] in abc) and (res != \"%_\" and res != \"_%\" and \"\\n\" not in res):\n",
    "                    combinations.append([res])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_validation(txt):\n",
    "    \"\"\"\n",
    "    Get all 2 letter combinations in text.\n",
    "    Different funtion was made to return in correct form\n",
    "    @param  txt: tekst waat combinaties uit gehaald worden\n",
    "    @return    : lijst met combinaties in tekst\n",
    "    \"\"\"\n",
    "    combinations = []\n",
    "    for line in txt:\n",
    "        temp = []\n",
    "        for letter in range(0, len(line)):  \n",
    "            try:\n",
    "                res = line[letter] + line[letter + 1]\n",
    "                # leesteken + spatie is niet relevant dus die combinaties kunnen eruit. \"\\n\" zitten er ook tussen en die kunnen ook weg\n",
    "                # en check of beide letters wel in het (aangepaste) alfabet zitten\n",
    "                if (res[0] in abc and res[-1] in abc) and (res != \"%_\" and res != \"_%\" and \"\\n\" not in res):\n",
    "                    temp.append(res)\n",
    "            except:\n",
    "                continue\n",
    "        combinations.append(temp)\n",
    "    \n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reducer.py\n",
    "'reducer' Maakt een matrix met van 28 bij 28 (ons alfabet is 28 lang) en vult per combinatie in hoevaak die voorkomt in een zin.\n",
    "\n",
    "'reducer_chance_matrix' Maakt een matrix met de procent kans dat een bepaalde 2 letter combinatie voorkomt.\n",
    "\n",
    "'reducer_final' \n",
    "De matrices zijn gevuld met kansen. Per combinatie die in een zin voorkomt\n",
    "pakt het algoritme de bijbehorende kans en telt die bij de totale kans dat een\n",
    "zin nederlands of engels is op. De taal met het hoogste getal aan het einde \n",
    "wordt als waarheid genomen.\n",
    "\n",
    "We hebben onze methode gebaseerd op een comment uit de volgende blogpost: https://stackoverflow.com/questions/7670427/how-does-language-detection-work/18197422. De comment in kwestie is: \n",
    "\n",
    "\n",
    "'Take the Wikipedia in English. Check what is the probability that after the letter 'a' comes a 'b' (for example) and do that for all the combination of letters, you will end up with a matrix of probabilities.\n",
    "\n",
    "If you do the same for the Wikipedia in different languages you will get different matrices for each language.\n",
    "\n",
    "To detect the language just use all those matrices and use the probabilities as a score, let say that in English you'd get this probabilities:\n",
    "\n",
    "t->h = 0.3 h->e = .2\n",
    "\n",
    "and in the Spanish matrix you'd get that\n",
    "\n",
    "t->h = 0.01 h->e = .3\n",
    "\n",
    "The word 'the', using the English matrix, would give you a score of 0.3+0.2 = 0.5 and using the Spanish one: 0.01+0.3 = 0.31\n",
    "\n",
    "The English matrix wins so that has to be English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(c):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    matrix = numpy.zeros((28, 28))\n",
    "    for combination in c:\n",
    "        left, right = combination[0], combination[-1]\n",
    "        try:\n",
    "            matrix[abc.index(left)][abc.index(right)] += 1 # find right place in matrix and add 1\n",
    "        except:\n",
    "            # double check: if one of the letters isnt in the alphabet skip this one and continue\n",
    "            continue \n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer_chance_matrix(m):\n",
    "    \"\"\"\n",
    "    Convert a frequence matrix to a chance matrix\n",
    "    \"\"\"\n",
    "    total = numpy.sum(m) # total letter combinations analysed\n",
    "    \n",
    "    with numpy.nditer(m, op_flags=['readwrite']) as it:\n",
    "        for x in it:\n",
    "            if x != 0:\n",
    "                x[...] = round(x / total * 100, 4) # chance x to its chance that it occurs\n",
    "            \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer_final(eng_m, nl_m, c):\n",
    "    \"\"\"\n",
    "    method: https://stackoverflow.com/a/18197422\n",
    "    @param eng_m: english trained matrix numpy array\n",
    "    @param nl_m: dutch trained matrix numpy array\n",
    "    @param c: list van combinaties die voorkomen per zin\n",
    "    \"\"\"\n",
    "    nl_count = 0    # houdt bij hoeveel nederlandse zinnen er zijn gevonden\n",
    "    eng_count = 0   # houdt bij hoveel engelse zinnen er zijn gevonden\n",
    "    for line in c:  # loopt door de tekst heen per line\n",
    "        # De matrices zijn gevuld met kansen. Per combinatie die in een zin voorkomt\n",
    "        # pakt het algoritme de bijbehorende kans en telt die bij de totale kans dat een\n",
    "        # zin nederlands of engels is op. De taal met het hoogste getal aan het einde \n",
    "        # wordt als waarheid genomen.\n",
    "        eng = 0   \n",
    "        nl = 0\n",
    "        for combination in line:\n",
    "            left, right = abc.index(combination[0]), abc.index(combination[-1]) # vind juiste index voor matrices\n",
    "            oem = eng_m[left][right]    # On English Matrix. De kans dat de combinatie voorkomt in het engels\n",
    "            odm = nl_m[left][right]     # On Dutch Matrix. De kans dat de combinatie voorkomt in het engels\n",
    "            eng += oem  # tel de kans op bij het totaal (voor sepcifieke zin)\n",
    "            nl += odm\n",
    "        \n",
    "        # er is nu een complete zin gecheckt -> kijk welk getal groter is en tel één bij de telling op\n",
    "        # Een gelijkspel zal zeer waarschijnlijk niet voorkomen omdat de kansen op 3 decimalen zijn afgerond\n",
    "        if eng > nl:\n",
    "            eng_count += 1\n",
    "        else:\n",
    "            nl_count += 1\n",
    "        \n",
    "        #reset waardes voor zin en ga door naar de volgende zin\n",
    "        eng, nl = 0, 0  \n",
    "    \n",
    "    return nl_count, eng_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_matrix.py\n",
    "Hier worden de matrices getraind, en worden ze opgeslagen als een .npy bestand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = ['eng', 'nl']\n",
    "\n",
    "\n",
    "def train_matrix(txt, lang):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    matrix = numpy.zeros((28, 28))\n",
    "    for line in txt:\n",
    "        m = reducer(line)\n",
    "        matrix = numpy.add(matrix, m)\n",
    "    \n",
    "    chance_m = reducer_chance_matrix(matrix)\n",
    "\n",
    "    numpy.save(\"trained_matrix/\" + lang + \"_trained\", chance_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    for x in LANGUAGES:\n",
    "        path = \"train_\" + x + \"/train_data\"\n",
    "        lines_list = mapper_get_lines(path)\n",
    "        updated_text = mapper_replace_punct(lines_list, leestekens)\n",
    "        print(updated_text[0])\n",
    "        combi_list = filter_training(updated_text)\n",
    "        print(combi_list[0:50])\n",
    "\n",
    "        train_matrix(combi_list, x)\n",
    "\n",
    "#train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main.py\n",
    "Dit is de main functie, hier wordt alles in beweging gezet en uitgevoerd, ook wordt de uitkomst hier weergegeven.\n",
    "Ook wordt hier weergegeven hoe de zin eruit ziet nadat alle spaties en leestekens weggehaald zijn, en daarna worden alle combinaties van die zin weergegeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_be_generously_rewarded_by_nasa%__young_descended_those_final_few\n",
      "['ti', 'im', 'me', 'e_', '_b', 'be', 'e_', '_g', 'ge', 'en', 'ne', 'er', 'ro', 'ou', 'us', 'sl', 'ly', 'y_', '_r', 're', 'ew', 'wa', 'ar', 'rd', 'de', 'ed', 'd_', '_b', 'by', 'y_', '_n', 'na', 'as', 'sa', 'a%', '__', '_y', 'yo', 'ou', 'un', 'ng', 'g_', '_d', 'de', 'es', 'sc', 'ce', 'en', 'nd', 'de', 'ed', 'd_', '_t', 'th', 'ho', 'os', 'se', 'e_', '_f', 'fi', 'in', 'na', 'al', 'l_', '_f', 'fe', 'ew']\n",
      "In deze tekst zijn 74 Nederlandse zinnen gevonden, en 117 Engelse zinnen.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    \"\"\"\n",
    "\n",
    "    lines_list = mapper_get_lines(\"validation\")\n",
    "    updated_text = mapper_replace_punct(lines_list, leestekens)\n",
    "    print(updated_text[0])\n",
    "    combi_list = filter_validation(updated_text)\n",
    "    print(combi_list[0])\n",
    "\n",
    "    nl, eng = numpy.load('trained_matrix/nl_trained.npy'), numpy.load('trained_matrix/eng_trained.npy')\n",
    "    result = reducer_final(eng, nl, combi_list)\n",
    "    print(f'In deze tekst zijn {result[0]} Nederlandse zinnen gevonden, en {result[1]} Engelse zinnen.')\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
